---
title: "Homework 3"
author: E. Brennan Bollman
date: '`r format(Sys.time(), "%y-%m-%d")`'
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom")) 

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d()
scale_fill_discrete = scale_fill_viridis_d()
```

## Problem 1

##### Step 1: Describe the instacart dataset. 

```{r}
data("instacart")
instacart
```

This dataset contains `r nrow(instacart)` rows of individual product orders from Instacart and `r ncol(instacart)` columns of variables such as user ID, product ID, and day and hour of the week at which the order was placed. More detailed information about the individual items is also available: product names, whether the product had been ordered previously, and the departments / aisles in which a product can be found. The dataset contains information from `r instacart %>% distinct(user_id) %>% count()` unique users who ordered `r instacart %>% distinct(product_id) %>% count()` distinct products. 

##### Step 2: Identify the most in-demand aisles.

Count the number of aisles, and identify which aisles have most items ordered from them.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

The dataset contains 134 distinct aisles. "Fresh vegetables" and "fresh fruits" are ordered from most frequently, with nearly double the number of item orders than the third highest in-demand aisle, "packaged vegetables fruits"---which are then followed by "yogurt" and "packaged cheese."

##### Step 3: Plot aisle popularity. 

Create a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered, and arranging plot sensibly. Need to first count by aisle, then filter by item count >10,000. Should rotate x-axis labels so it is readable. Finally, re-order aisle according to n, from the aisle with the lowest number of items ordered to that with the highest ordered. 

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() + 
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```

This plot demonstrates again that vegetables and fruits are much more popular than other aisles!

##### Step 4: Demonstrate the most popular items in select aisles.

Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table. Will filter by the above aisles, count the most popular aisles in each. Then will rank each of the 3 aisles, for only the top 3 n's, and arrange them most popular to least popular for each aisle.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```


##### Step 5: Demonstrate mean hour of day for select items ordered, on each day of the week. 

Make a table showing the mean hour of the day at which "Pink Lady Apples" and "Coffee Ice Cream" are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table). First, filter only these items. Then group by the products in question and day of week, and summarize to find the mean hour of the day at which each item is ordered. Finally, reformat table for easier visualization. 

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable()
```

For every day of the week, coffee ice cream is ordered later in the day than apples. Dessert is important.

## Problem 2

##### Step 1: Read-in and tidy the activity dataset.

First, pivot longer to list activity_count for each minute_of_day in long-form (tidy). Create wkday_vs_wknd variable, and make both this and day variable factors. Extract substring from "activity.1" etc values such that the remaining character form of 1 - 1440 can be converted to dbl form.  

```{r}
activity_df = 
  read_csv("./data/accel_data.csv") %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "minute_of_day",
    values_to = "activity_count"
  ) %>% 
  mutate(day = factor(day),
         minute_of_day = as.numeric(str_sub(minute_of_day, 10)),
         wkday_vs_wknd = case_when(day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") 
                                   ~ "weekday",
                             day %in% c("Saturday", "Sunday") ~ "weekend"),
         wkday_vs_wknd = factor(wkday_vs_wknd)
         ) %>% 
  relocate(week, day, wkday_vs_wknd, minute_of_day, activity_count)

activity_df
```

##### Step 2: Aggregate minute activity into daily activity count.

First, group by week and day. Then compute the sum of activity_count as total_activity. Finally, format table for ease of reading. 

```{r}
activity_df %>% 
  group_by(week, day) %>% 
  summarize(total_activity = sum(activity_count)) %>% 
  pivot_wider(
    names_from = day,
    values_from = total_activity
  ) %>%
  relocate(week, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday) %>% 
  knitr::kable()
```

This individual tended to perform similar levels of total daily activity on weekends as on weekdays during the first 3 weeks of data collection. However, in the 4th and 5th week of data collection, he performed noticeably less activity on weekends, particularly on Saturdays. 

##### Step 3: Make plot of activity over course of each day.

Want to plot activity_count (y) vs minute_of_day. Since these are both continuous variables, start with scatterplot and add geom_line() to connect points, grouped by day_id with the idea of creating 35 lines connecting each day's activity variation over minutes during day. Each day of week is color. 

```{r}
activity_df %>% 
  ggplot(aes(x = minute_of_day, y = activity_count, group = day_id, color = day)) + 
  geom_point() +
  geom_line() + 
  labs(
    title = "Line plot of Activity over Course of Day",
    x = "Minutes of the Day",
    y = "Activity Count"
  ) + 
  viridis::scale_color_viridis(
    name = "day",
    discrete = TRUE
  )
```

This plot is hard to interpret given the volume of data. However, it appears as though the bulk of each day of the week was spent with activity_count < 2500. Even lower activity counts are seen in the first 250 and last 250 minutes of the day, likely representing time sleeping. Some outliers exist for periods in the middle 1/3 of the day generally, which was less common on Wednesdays (no exercise on hump day?).

```{r}
activity_df %>%
  mutate(
    day = forcats::fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", 
                                      "Sunday"))
  ) %>% 
  ggplot(aes(x = minute_of_day, y = activity_count, group = day_id, color = day)) +
  geom_boxplot() + 
  scale_y_continuous(
    breaks = seq(from = 0, to = 8000, by = 500)
  ) + 
  labs(
    title = "Boxplot of Activity over Course of Day",
    x = "Minutes of the Day",
    y = "Activity Count"
  ) + 
  viridis::scale_color_viridis(
    name = "day",
    discrete = TRUE
  )
```

A quick boxplot on the same concept also demonstrates that all of the 'boxes' are low activity, such that 75% of activity counts for most days were 500 or fewer, suggesting this individual spends most of the day at rest or sedentary with brief periods of increased activity. 

## Problem 3
Homework 3
================
E. Brennan Bollman
20-10-10

## Problem 1

##### Step 1: Describe the instacart dataset.

``` r
data("instacart")
instacart
```

    ## # A tibble: 1,384,617 x 15
    ##    order_id product_id add_to_cart_ord… reordered user_id eval_set order_number
    ##       <int>      <int>            <int>     <int>   <int> <chr>           <int>
    ##  1        1      49302                1         1  112108 train               4
    ##  2        1      11109                2         1  112108 train               4
    ##  3        1      10246                3         0  112108 train               4
    ##  4        1      49683                4         0  112108 train               4
    ##  5        1      43633                5         1  112108 train               4
    ##  6        1      13176                6         0  112108 train               4
    ##  7        1      47209                7         0  112108 train               4
    ##  8        1      22035                8         1  112108 train               4
    ##  9       36      39612                1         0   79431 train              23
    ## 10       36      19660                2         1   79431 train              23
    ## # … with 1,384,607 more rows, and 8 more variables: order_dow <int>,
    ## #   order_hour_of_day <int>, days_since_prior_order <int>, product_name <chr>,
    ## #   aisle_id <int>, department_id <int>, aisle <chr>, department <chr>

This dataset contains 1384617 rows of individual product orders from
Instacart and 15 columns of variables such as user ID, product ID, and
day and hour of the week at which the order was placed. More detailed
information about the individual items is also available: product names,
whether the product had been ordered previously, and the departments /
aisles in which a product can be found. The dataset contains information
from 131209 unique users who ordered 39123 distinct products.

##### Step 2: Identify the most in-demand aisles.

Count the number of aisles, and identify which aisles have most items
ordered from them.

``` r
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # … with 124 more rows

The dataset contains 134 distinct aisles. “Fresh vegetables” and “fresh
fruits” are ordered from most frequently, with nearly double the number
of item orders than the third highest in-demand aisle, “packaged
vegetables fruits”—which are then followed by “yogurt” and “packaged
cheese.”

##### Step 3: Plot aisle popularity.

Create a plot that shows the number of items ordered in each aisle,
limiting this to aisles with more than 10000 items ordered, and
arranging plot sensibly. Need to first count by aisle, then filter by
item count \>10,000. Should rotate x-axis labels so it is readable.
Finally, re-order aisle according to n, from the aisle with the lowest
number of items ordered to that with the highest ordered.

``` r
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() + 
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw3_ebb2166_files/figure-gfm/unnamed-chunk-3-1.png" width="90%" />

This plot demonstrates again that vegetables and fruits are much more
popular than other aisles\!

##### Step 4: Demonstrate the most popular items in select aisles.

Make a table showing the three most popular items in each of the aisles
“baking ingredients”, “dog food care”, and “packaged vegetables
fruits”. Include the number of times each item is ordered in your
table. Will filter by the above aisles, count the most popular aisles in
each. Then will rank each of the 3 aisles, for only the top 3 n’s, and
arrange them most popular to least popular for each aisle.

``` r
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

##### Step 5: Demonstrate mean hour of day for select items ordered, on each day of the week.

Make a table showing the mean hour of the day at which “Pink Lady
Apples” and “Coffee Ice Cream” are ordered on each day of the week;
format this table for human readers (i.e. produce a 2 x 7 table). First,
filter only these items. Then group by the products in question and day
of week, and summarize to find the mean hour of the day at which each
item is ordered. Finally, reformat table for easier visualization.

``` r
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable()
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

| product\_name    |        0 |        1 |        2 |        3 |        4 |        5 |        6 |
| :--------------- | -------: | -------: | -------: | -------: | -------: | -------: | -------: |
| Coffee Ice Cream | 13.77419 | 14.31579 | 15.38095 | 15.31818 | 15.21739 | 12.26316 | 13.83333 |
| Pink Lady Apples | 13.44118 | 11.36000 | 11.70213 | 14.25000 | 11.55172 | 12.78431 | 11.93750 |

For every day of the week, coffee ice cream is ordered later in the day
than apples. Dessert is important.

## Problem 2

##### Step 1: Read-in and tidy the activity dataset.

First, pivot longer to list activity\_count for each minute\_of\_day in
long-form (tidy). Create wkday\_vs\_wknd variable, and make both this
and day variable factors. Extract substring from “activity.1” etc values
such that the remaining character form of 1 - 1440 can be converted to
dbl form.

``` r
activity_df = 
  read_csv("./data/accel_data.csv") %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "minute_of_day",
    values_to = "activity_count"
  ) %>% 
  mutate(day = factor(day),
         minute_of_day = as.numeric(str_sub(minute_of_day, 10)),
         wkday_vs_wknd = case_when(day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") 
                                   ~ "weekday",
                             day %in% c("Saturday", "Sunday") ~ "weekend"),
         wkday_vs_wknd = factor(wkday_vs_wknd)
         ) %>% 
  relocate(week, day, wkday_vs_wknd, minute_of_day, activity_count)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
activity_df
```

    ## # A tibble: 50,400 x 6
    ##     week day    wkday_vs_wknd minute_of_day activity_count day_id
    ##    <dbl> <fct>  <fct>                 <dbl>          <dbl>  <dbl>
    ##  1     1 Friday weekday                   1           88.4      1
    ##  2     1 Friday weekday                   2           82.2      1
    ##  3     1 Friday weekday                   3           64.4      1
    ##  4     1 Friday weekday                   4           70.0      1
    ##  5     1 Friday weekday                   5           75.0      1
    ##  6     1 Friday weekday                   6           66.3      1
    ##  7     1 Friday weekday                   7           53.8      1
    ##  8     1 Friday weekday                   8           47.8      1
    ##  9     1 Friday weekday                   9           55.5      1
    ## 10     1 Friday weekday                  10           43.0      1
    ## # … with 50,390 more rows

##### Step 2: Aggregate minute activity into daily activity count.

First, group by week and day. Then compute the sum of activity\_count as
total\_activity. Finally, format table for ease of reading.

``` r
activity_df %>% 
  group_by(week, day) %>% 
  summarize(total_activity = sum(activity_count)) %>% 
  pivot_wider(
    names_from = day,
    values_from = total_activity
  ) %>%
  relocate(week, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday) %>% 
  knitr::kable()
```

    ## `summarise()` regrouping output by 'week' (override with `.groups` argument)

| week |    Monday |  Tuesday | Wednesday | Thursday |   Friday | Saturday | Sunday |
| ---: | --------: | -------: | --------: | -------: | -------: | -------: | -----: |
|    1 |  78828.07 | 307094.2 |    340115 | 355923.6 | 480542.6 |   376254 | 631105 |
|    2 | 295431.00 | 423245.0 |    440962 | 474048.0 | 568839.0 |   607175 | 422018 |
|    3 | 685910.00 | 381507.0 |    468869 | 371230.0 | 467420.0 |   382928 | 467052 |
|    4 | 409450.00 | 319568.0 |    434460 | 340291.0 | 154049.0 |     1440 | 260617 |
|    5 | 389080.00 | 367824.0 |    445366 | 549658.0 | 620860.0 |     1440 | 138421 |

This individual tended to perform similar levels of total daily activity
on weekends as on weekdays during the first 3 weeks of data collection.
However, in the 4th and 5th week of data collection, he performed
noticeably less activity on weekends, particularly on Saturdays.

##### Step 3: Make plot of activity over course of each day.

Want to plot activity\_count (y) vs minute\_of\_day. Since these are
both continuous variables, start with scatterplot and add geom\_line()
to connect points, grouped by day\_id with the idea of creating 35 lines
connecting each day’s activity variation over minutes during day. Each
day of week is color.

``` r
activity_df %>% 
  ggplot(aes(x = minute_of_day, y = activity_count, group = day_id, color = day)) + 
  geom_point() +
  geom_line() + 
  labs(
    title = "Line plot of Activity over Course of Day",
    x = "Minutes of the Day",
    y = "Activity Count"
  ) + 
  viridis::scale_color_viridis(
    name = "day",
    discrete = TRUE
  )
```

<img src="p8105_hw3_ebb2166_files/figure-gfm/unnamed-chunk-8-1.png" width="90%" />

This plot is hard to interpret given the volume of data. However, it
appears as though the bulk of each day of the week was spent with
activity\_count \< 2500. Even lower activity counts are seen in the
first 250 and last 250 minutes of the day, likely representing time
sleeping. Some outliers exist for periods in the middle 1/3 of the day
generally, which was less common on Wednesdays (no exercise on hump
day?).

``` r
activity_df %>%
  mutate(
    day = forcats::fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", 
                                      "Sunday"))
  ) %>% 
  ggplot(aes(x = minute_of_day, y = activity_count, group = day_id, color = day)) +
  geom_boxplot() + 
  scale_y_continuous(
    breaks = seq(from = 0, to = 8000, by = 500)
  ) + 
  labs(
    title = "Boxplot of Activity over Course of Day",
    x = "Minutes of the Day",
    y = "Activity Count"
  ) + 
  viridis::scale_color_viridis(
    name = "day",
    discrete = TRUE
  )
```

<img src="p8105_hw3_ebb2166_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

A quick boxplot on the same concept also demonstrates that all of the
‘boxes’ are low activity, such that 75% of activity counts for most
days were 500 or fewer, suggesting this individual spends most of the
day at rest or sedentary with brief periods of increased activity.

## Problem 3
